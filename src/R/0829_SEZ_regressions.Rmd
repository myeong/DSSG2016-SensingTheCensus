---
title: "Network Regressions and Predictions for Milano, SEZ-levl"
author: "Myeong Lee"
date: "August 29, 2016"
output: html_document
---

This is a regression analysis for CDR and poverty data following the methods presented by Chirs (WWW 16). 

```{r, echo=FALSE}
library(maps)
library(geosphere)
library(readr)
library(dplyr)
library(magrittr)
library(lubridate)
library(rgdal)
library(raster)
library(rgeos)
require(ggplot2)
library(cwhmisc)
library(utils)
library(rpart)
library(stringr)
library(hydroGOF)
library(fields)
library(MASS)
library(e1071)
library(raster)
library(reshape2)
library(igraph)
```

# Random Baseline
```{r}
setwd("/Users/myeong/git/DSSG/DSSG2016-SensingTheCensus/")
census = readOGR("data/GeoJSON/milano_census_sez.geojson", "OGRGeoJSON")  %>% spTransform(CRS("+proj=utm +zone=32 +datum=WGS84"))
raw = read_delim("data/census/R03_indicatori_2011_sezioni.csv", delim = ";",col_names = TRUE ) 

cdr = read_delim("data/CDR/hash/0831_region_time.csv", delim = ",",col_names = TRUE ) 
# street = read_delim("data/census/centrality_ace.csv", delim = ",",col_names = TRUE ) 
# oa <-  read_delim("data/OSM/offering_advantage.csv", delim = ",",col_names = TRUE ) 
deprivation = read_delim("data/census/temporal_deprivation.csv", delim = ",",col_names = TRUE ) 

# census@data$SEZ2011 <- as.factor(census@data$SEZ2011)

# street$ACE <- as.character(street$ACE)
# street$ACE <- as.factor(street$ACE)
# deprivation$SEZ <- as.character(deprivation$SEZ)
# deprivation$SEZ <- as.factor(deprivation$SEZ)
# raw$SEZ2011 <- as.character(raw$SEZ2011)
# raw$SEZ2011 <- as.factor(raw$SEZ2011)
# oa$ACE <- as.character(oa$ACE)
# oa$ACE <- as.factor(oa$ACE)

networks = read_delim("data/CDR/hash/sez_network.csv", delim = ",",col_names = TRUE ) 
# networks$time = paste(networks$month, str_pad(networks$day, 2, pad = "0"), str_pad(networks$hour, 2, pad = "0"), sep="")
# networks$time <- as.integer(networks$time)
# networks <- arrange(networks,time)

get_introversion <- function(df){
  introvert <- df[df$source==df$dest,]
  introvert <- introvert %>% dplyr::group_by(source) %>% summarize(sum(call))
  
  extrovert <- df[df$source!=df$dest,]
  extrovert <- extrovert %>% dplyr::group_by(source) %>% summarize(sum(call))
  
  introvert <-  introvert %>% left_join(extrovert, by = c("source" = "source"))
  colnames(introvert) <- c("source", "inside", "outside")
  introvert$region_based_rate <- introvert$inside/introvert$outside  
  
  introvert$source <- as.factor(introvert$source)  
  
  return(introvert)
}

introversion <- get_introversion(networks)
introversion$source <- as.numeric(levels(introversion$source))[introversion$source]

census@data <-  census@data %>% left_join(introversion, by = c("SEZ2011" = "source"))
census@data <- census@data %>% left_join(raw, by = c("SEZ2011"))


# Total Time Aggregation
graph <- networks %>% dplyr::group_by(source, dest) %>% summarize(sum(call))
colnames(graph) <- c("source", "dest","weight")
total_g <- graph.data.frame(graph)

# Visualization of the Graph
# max_call <- max(E(total_g)$call)
# plot.igraph(total_g, vertex.label=V(total_g)$name, layout=layout.fruchterman.reingold, edge.color="black", edge.width=E(total_g)$weight/max_call)

# Weighted PageRank (directed)
page_rank_g <- page_rank(total_g, vids = V(total_g), directed = TRUE)
page_rank <- as.data.frame(page_rank_g$vector)
page_rank$SEZ2011 <- rownames(page_rank)
page_rank$SEZ2011 <- as.numeric(page_rank$SEZ2011)
census@data <-  census@data %>% left_join(page_rank, by = c("SEZ2011"))
census@data$page_rank <- as.numeric(census@data$page_rank)
sha <- shapiro.test(sample(census@data$page_rank, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$page_rank <- log(census@data$page_rank)
}

# Eigenvector Centraility
eigen_cent <- eigen_centrality(total_g, directed = TRUE)
eigen_cent <- as.data.frame(eigen_cent$vector)
eigen_cent$SEZ2011 <- rownames(eigen_cent)
eigen_cent$SEZ2011 <- as.numeric(eigen_cent$SEZ2011)
census@data <-  census@data %>% left_join(eigen_cent, by = c("SEZ2011"))
census@data$eigen_cent <- as.numeric(census@data$eigen_cent)
sha <- shapiro.test(sample(census@data$eigen_cent, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$eigen_cent <- log(census@data$eigen_cent)
}

# Entropy of Edges
entropy <- diversity(total_g)
entropy <- as.data.frame(entropy)
entropy$SEZ2011 <- rownames(entropy)
entropy$SEZ2011 <- as.numeric(entropy$SEZ2011)
census@data <-  census@data %>% left_join(entropy, by = c("SEZ2011"))
sha <- shapiro.test(sample(census@data$entropy, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$entropy <- log(census@data$entropy)
}


rm(networks)
rm(graph)

### Total Call Volume

cdr_agg <- cdr %>% dplyr::group_by(region_id) %>% summarize(calls = sum(adjusted_callIn + adjusted_callOut, na.rm=TRUE))

census@data <- census@data %>% left_join(cdr_agg, by = c("SEZ2011" = "region_id"))

sha <- shapiro.test(sample(census@data$calls, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$calls <- log(census@data$calls)
}

census@data <- census@data %>% left_join(deprivation, by = c("SEZ2011"="SEZ"))

# census@data <- census@data %>% left_join(street, by = c("ACE"))
# census@data <- census@data %>% left_join(oa, by = c("ACE"))

plot(density(census@data$dep11, na.rm=TRUE))
shapiro.test(sample(census@data$dep11, 5000, replace=FALSE))

qqnorm(census@data$dep11)
qqline(census@data$dep11, col = 2)

census@data <- census@data[names(census@data) != ""]
# generate random drwas from two distinct normal distribution -- the final vector follows the distribution of observed data (deprivation)
rand1 <- rnorm (5000, mean(census@data$dep11,na.rm=TRUE), sd(census@data$dep11,na.rm=TRUE))
rand2 <- rnorm (5000, mean(census@data$dep11,na.rm=TRUE), sd(census@data$dep11,na.rm=TRUE))
rand <- c(rand1, rand2)
rand_data <- sample(rand, length(census@data$dep11), replace = FALSE, prob = NULL)
census@data$rand_base <- rand_data
sha <- shapiro.test(sample(census@data$rand_base, 5000, replace=FALSE))

# MAE and Spearman's rank coefficient: comparion between the data and randomly generated poverty scores
pred <- predict(lm(dep11 ~ rand_base, data=census@data, na.action=na.exclude))
mae <- mae(pred,census@data$dep11, na.rm=TRUE)
mae
rho <- cor.test(pred,census@data$dep11, method="spearman")
rho$estimate
```

# Population-density baseline
```{r}
census@data$density <- census@data$P1/raster::area(census)
pca_baseline <- lm(dep11 ~ log(density), data=census@data)
summary(pca_baseline)

milano_baseline <- lm(dep11 ~ density, data=census@data)
summary(milano_baseline)

sha <- shapiro.test(sample(census@data[is.finite(census@data$density),]$density, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$density <- log(census@data$density)
}
```

# Spaital-Lag Baseline based on 2001 deprivation index
```{r}
census@data$spatial_lag <- NA

trueCentroids = gCentroid(census,byid=TRUE, id = as.vector(census@data$SEZ2011))
popdists <- as.matrix(rdist.earth(cbind(trueCentroids$x, trueCentroids$y), miles = F, R = NULL))

# calculating spatial lag
for (i in 1:length(trueCentroids)){
  print(i)
  k <- sapply(popdists[i,], function(x) 1/(x*x))
  k[is.infinite(k)] <- 0 
  k <- sapply(k, function(x) x/sum(k))  
  
  census@data$spatial_lag[i] <- sum(census@data$dep01 * k, na.rm = TRUE)
}

sha <- shapiro.test(sample(census@data$spatial_lag, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$spatial_lag <- log(census@data$spatial_lag)
}

```


# CDR features



### Introversion
```{r}
sha <- shapiro.test(sample(census@data$region_based_rate, 5000, replace=FALSE))
if (sha$p.value > 0.05) {
  census@data$region_based_rate <- log(census@data$region_based_rate)
}
```


### Network Advantage
```{r}

```

```{r}
# sha <- shapiro.test(census@data$betweenness)
# if (sha$p.value > 0.05) {
#   census@data$betweenness <- log(census@data$betweenness)
# }
# sha <- shapiro.test(census@data$closeness)
# if (sha$p.value > 0.05) {
#   census@data$closeness <- log(census@data$closeness)
# }
# sha <- shapiro.test(census@data$bar)
# if (sha$p.value > 0.05) {
#   census@data$bar <- log(census@data$bar)
# }
# sha <- shapiro.test(census@data$bank)
# if (sha$p.value > 0.05) {
#   census@data$bank <- log(census@data$bank)
# }
# sha <- shapiro.test(census@data$bicycle_parking)
# if (sha$p.value > 0.05) {
#   census@data$bicycle_parking <- log(census@data$bicycle_parking)
# }
```


# Predictions

### Linear Regression

```{r}
setwd("/Users/myeong/git/DSSG/DSSG2016-SensingTheCensus")
census = read.csv("data/0917_features.csv")  

colnames(census)[9] <- "dep11"
colnames(census)[10] <- "dep01"

census$dep_class_7 <- as.factor(census$dep_class_7)

census <- subset(census, select=c(dep_class_7, rand_base, density, spatial_lag, spatial_lag_square, dep01, dep11, calls, entropy, eigen_cent, page_rank, region_based_rate, commercial, third_places, comm_service, closeness, betweenness, SEZ2011))

cluster2 <- read_delim("data/CDR/hash/k2_cluster.csv", delim=",", col_names=TRUE)
colnames(cluster2) <- c("SEZ2011", "cluster2")

cluster3 <- read_delim("data/CDR/hash/k3_cluster.csv", delim=",", col_names=TRUE)
colnames(cluster3) <- c("SEZ2011", "cluster3")

census <- census %>% left_join(cluster2, by = c("SEZ2011"))
census$cluster2 <- as.factor(census$cluster2)

census <- census %>% left_join(cluster3, by = c("SEZ2011"))
census$cluster3 <- as.factor(census$cluster3)
```



```{r}
proportions <- seq(50, 90, 5)
rand_error_table <- matrix(NA,nrow=length(proportions),ncol=4)
colnames(rand_error_table) <- c("train", "rho", "minmax", "mae")
num_test <- 1

calculate_error_table <- function (variable){
  
  for (i in 1:length(proportions) ){
    temp_table <- data.frame(NA,nrow=num_test,ncol=3)
    colnames(temp_table) <- c("rho", "minmax", "mape")
    
    for (j in 1:num_test){
      index <- 1:nrow(census)
      testindex <- sample(index, trunc(length(index) * (100-proportions[i]) / 100 ))
      testset <- census[testindex,]
      row.names(testset) <- testset$SEZ2011
      trainset <- census[-testindex,]
      
      if (variable == "random"){   
        rand1 <- rnorm (5000, mean(census$dep11, na.rm=TRUE), sd(census$dep11, na.rm=TRUE))
        rand2 <- rnorm (5000, mean(census$dep11, na.rm=TRUE), sd(census$dep11, na.rm=TRUE))
        rand <- c(rand1, rand2)        
        census$rand_base <- sample(rand, length(census$dep11), replace = FALSE, prob = NULL)
        model <- lm (dep11 ~ rand_base, data=trainset)
      } else if (variable == "density"){
        model <- lm (dep11 ~ density, data=trainset)
      } else if (variable == "past"){
        model <- lm (dep11 ~ dep01, data=trainset, na.action=na.omit)
      }else if (variable == "spatial_lag_square"){
        model <- lm (dep11 ~ spatial_lag_square, data=trainset, na.action=na.omit)
      } else if (variable == "volume"){
        model <- lm (dep11 ~ calls, data=trainset, na.action=na.omit)
      } else if (variable == "introversion"){
        model <- lm (dep11 ~ region_based_rate, data=trainset, na.action=na.omit)
      } else if (variable == "page_rank"){
        model <- lm (dep11 ~ page_rank, data=trainset, na.action=na.omit)
      } else if (variable == "eigen_cent"){
        model <- lm (dep11 ~ eigen_cent, data=trainset, na.action=na.omit)
      } else if (variable == "entropy"){
        model <- lm (dep11 ~ entropy, data=trainset, na.action=na.omit)
      } else if (variable == "past_cdr"){
        model <- lm (dep11 ~ scale(calls) + scale(region_based_rate) + scale(page_rank) + scale(eigen_cent) + scale(entropy) + scale(dep01), data=trainset, na.action=na.omit)
      } else if (variable == "past_lag"){
        model <- lm (dep11 ~ scale(dep01) + scale(spatial_lag_square) , data=trainset,na.action=na.omit)
      } else if (variable == "past_lag_cdr"){
        model <- lm (dep11 ~ scale(calls) + scale(region_based_rate) + scale(page_rank) + scale(eigen_cent) + scale(entropy) + scale(dep01) + scale(spatial_lag_square), data=trainset, na.action=na.omit)
      } else if (variable == "entoropy_lag"){
        model <- lm (dep11 ~ scale(entropy) + scale(spatial_lag_square), data=trainset, na.action=na.omit)
      } else if (variable == "cdr_lag"){
        model <- lm (dep11 ~ scale(spatial_lag_square) +scale(calls) + scale(region_based_rate) + scale(page_rank) + scale(eigen_cent) + scale(entropy), data=trainset, na.action=na.omit)
      } else if (variable == "betweenness"){
        model <- lm (dep11 ~ betweenness, data=trainset, na.action=na.omit)
      } else if (variable == "closeness"){
        model <- lm (dep11 ~ closeness, data=trainset, na.action=na.omit)
      } else if (variable == "c3"){
        model <- lm (dep11 ~ cluster3, data=trainset, na.action=na.omit)
      } else if (variable == "street_network"){
        model <- lm (dep11 ~ scale(closeness) + scale(betweenness), data=trainset)
      } else if (variable == "cdr"){
        model <- lm (dep11 ~ scale(calls) + scale(region_based_rate) + scale(page_rank) + scale(eigen_cent) + scale(entropy), data=trainset, na.action=na.omit)
      } else if (variable == "cdr_osm"){
        model <- lm (dep11 ~ scale(calls) + scale(region_based_rate) + scale(page_rank) + scale(eigen_cent) + scale(entropy) + scale(closeness) + scale(betweenness) + scale(bar) + scale(bicycle_parking), data=trainset, na.action=na.omit)
      }else if (variable == "bar"){
        model <- lm (dep11 ~ bar, data=trainset, na.action=na.omit)
      } else if (variable == "third_places"){
        model <- lm (dep11 ~ third_places, data=trainset, na.action=na.omit)
      }else if (variable == "commercial"){
        model <- lm (dep11 ~ commercial, data=trainset, na.action=na.omit)
      }else if (variable == "comm_service"){
        model <- lm (dep11 ~ comm_service, data=trainset, na.action=na.omit)
      }else if (variable == "bank"){
        model <- lm (dep11 ~ bank, data=trainset)
      } else if (variable == "bicycle_parking"){
        model <- lm (dep11 ~ bicycle_parking, data=trainset)
      } else if (variable == "oa_st"){
        model <- lm (dep11 ~ scale(bicycle_parking) + scale(bar) + scale(closeness) + scale(betweenness), data=trainset)
      } 
      
      
      # Visual representation
      # pred.w.plim <- predict(random, testset, interval = "prediction")
      # pred.w.clim <- predict(random, testset, interval = "confidence")
      # matplot(testset$rand_base, cbind(pred.w.clim, pred.w.plim[,-1]), lty = c(1,2,2,3,3), col=c("black", "red", "red", "blue", "blue"), type = "l", ylab = "predicted y")
      
      pred <- predict(model, testset)
      
      # Classification Rate Test (this is not a classification problem...)
      # pred_table <- table(pred = pred, true=testset$dep11)
      # prediction_rate <- sum(diag(pred_table))/sum(pred_table)
      # prediction_rate
      
      # Prediction Accuracy Test
      actuals_preds <- data.frame(cbind(actuals=testset$dep11, predicteds=pred))
    #   correlation_accuracy <- cor(actuals_preds)
      rho <- cor.test(actuals_preds$predicteds,actuals_preds$actuals, method="spearman")
    
      min_max_accuracy <- mean(apply(actuals_preds, 1, min) / apply(actuals_preds, 1, max)) 
      mape <- mae(actuals_preds$predicteds,actuals_preds$actuals, na.rm=TRUE)
#       mape <- mean(abs((actuals_preds$predicteds - actuals_preds$actuals))/actuals_preds$actuals)
      
      temp_table[j,] <- c(rho$estimate, min_max_accuracy, mape)
      print(rho)
    }
    temp_table <- apply(temp_table, 2, mean)     
              
    rand_error_table[i,] <- c(proportions[i], temp_table["rho"], temp_table["minmax"], temp_table["mape"])
  }
  rand_error_table <- as.data.frame(rand_error_table)
  return (rand_error_table)
}

#baselines
rand <- calculate_error_table ("random")
past <- calculate_error_table ("past")


density <- calculate_error_table ("density")
spatial_lag_square <- calculate_error_table ("spatial_lag_square")

#CDR
intro <- calculate_error_table ("introversion")
eigen_cent <- calculate_error_table ("eigen_cent")
entropy <- calculate_error_table ("entropy")
page_rank <- calculate_error_table ("page_rank")
cdr <- calculate_error_table ("cdr")
vol <- calculate_error_table ("volume")
c3 <- calculate_error_table ("c3")

betweenness <- calculate_error_table ("betweenness")
closeness <- calculate_error_table ("closeness")
third_places <- calculate_error_table ("third_places")
commercial <- calculate_error_table ("commercial")
comm_service <- calculate_error_table ("comm_service")




# Baseline Graph Drawing
draw_graph_base <- function (column){
  dd <- cbind(rand$train, rand[,column], density[,column], spatial_lag_square[,column], past[,column] )
  colnames(dd) <- c("train","random", "density", "spatial_lag_square", "past")

  dd <- as.data.frame(dd)
  df <- melt(dd, id.vars='train')
  colindex <- round(as.integer(as.factor(df$variable) ))
  
  ggplot(df, aes(x = train, y = value, shape=factor(variable), colour=factor(variable))) +
    geom_point(size = 3) +
    geom_line() +
    scale_x_continuous('Train Proportion (%)',limits=c(50,95)) + 
#     scale_y_continuous('Rho',limits=c(-0.07, 0.07)) +
    theme_bw() + 
    geom_hline(yintercept=0) + theme(legend.text=element_text(size=15))
}

draw_graph_base("mae")
draw_graph_base("minmax")
draw_graph_base("rho")


# CDR Graph Drawing
draw_graph2 <- function (column){
  dd <- cbind(rand$train, rand[,column], density[,column], cdr[,column], page_rank[,column],
              vol[,column], intro[,column], eigen_cent[,column], entropy[,column] )
  colnames(dd) <- c("train","random", "density", "cdr","page_rank", 
                    "call_volumne","introversion","eigen_cent","entropy")
  dd <- as.data.frame(dd)
  df <- melt(dd, id.vars='train')
  colindex <- round(as.integer(as.factor(df$variable) ))
  
  ggplot(df, aes(x = train, y = value, shape=factor(variable), colour=factor(variable))) +
    geom_point(size = 3) +
    geom_line() +
    scale_x_continuous('Train Proportion (%)',limits=c(50,95)) + 
  #   scale_y_continuous('Rho',limits=c(-0.1, 1)) +
    theme_bw() + 
    geom_hline(yintercept=0) + theme(legend.text=element_text(size=15))
}

draw_graph2("mae")
draw_graph2("minmax")
draw_graph2("rho")

past_cdr <- calculate_error_table ("past_cdr")
past_lag <- calculate_error_table ("past_lag")
past_lag_cdr <- calculate_error_table ("past_lag_cdr")
entoropy_lag <- calculate_error_table ("entoropy_lag")
cdr_lag <- calculate_error_table ("cdr_lag")

#combination
draw_comb <- function (column){
  dd <- cbind(rand$train, density[,column], past[,column],past_cdr[,column], 
              past_lag[,column], past_lag_cdr[,column], entoropy_lag[,column], cdr_lag[,column] )
  colnames(dd) <- c("train", "density", "past","past+CDR", 
                    "past+lag","past+lag+cdr","entropy+lag","cdr+lag")
  dd <- as.data.frame(dd)
  df <- melt(dd, id.vars='train')
  colindex <- round(as.integer(as.factor(df$variable) ))
  
  ggplot(df, aes(x = train, y = value, shape=factor(variable), colour=factor(variable))) +
    geom_point(size = 3) +
    geom_line() +
    scale_x_continuous('Train Proportion (%)',limits=c(50,95)) + 
  #   scale_y_continuous('Rho',limits=c(-0.1, 1)) +
    theme_bw() + 
    geom_hline(yintercept=0) + theme(legend.text=element_text(size=15))
}

draw_comb("mae")
draw_comb("minmax")
draw_comb("rho")

```

```{r}
#OSM
betweenness <- calculate_error_table ("betweenness")
closeness <- calculate_error_table ("closeness")
# street_network <- calculate_error_table ("street_network")
# cdr_osm <- calculate_error_table ("cdr_osm")
# bar <- calculate_error_table ("bar")
# bank <- calculate_error_table ("bank")
# bicycle_parking <- calculate_error_table ("bicycle_parking")
# oa_st <- calculate_error_table ("oa_st")
# 
# # OSM Graph Drawing
# draw_graph <- function (column){
#   dd <- cbind(rand$train, rand[,column], density[,column], betweenness[,column], closeness[,column], street_network[,column], bar[,column], bank[,column], bicycle_parking[,column], oa_st[,column] )
#   colnames(dd) <- c("train","random", "density", "betweenness", "closeness", "street_network", "bar", "bank", "bicycle_parking", "bar+bicycle+street")
# 
#   dd <- as.data.frame(dd)
#   df <- melt(dd, id.vars='train')
#   colindex <- round(as.integer(as.factor(df$variable) ))
#   
#   ggplot(df, aes(x = train, y = value, shape=factor(variable), colour=factor(variable))) +
#     geom_point(size = 3) +
#     geom_line() +
#     scale_x_continuous('Train Proportion (%)',limits=c(50,95)) + 
# #     scale_y_continuous('Rho',limits=c(-0.07, 0.07)) +
#     theme_bw() + 
#     geom_hline(yintercept=0) + theme(legend.text=element_text(size=15))
# }
# 
# draw_graph("mae")
# draw_graph("minmax")
# draw_graph("rho")
```

